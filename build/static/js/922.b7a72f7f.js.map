{"version":3,"file":"static/js/922.b7a72f7f.js","mappings":"84BAcA,KAAM,GACJ,yBACA,GAAI,MAAO,4jOAAY,uCAAwC,CAC7D,QAAS,MACT,aAAc,4jOAAY,8CAE9B,GAAI,GAAU,KAEP,YAA+B,CACpC,KAAM,CAAC,EAAwB,GAA6B,eAAS,IAC/D,CAAC,EAAY,GAAiB,eAAS,IACvC,CAAC,EAAc,GAAmB,eAAS,IAC3C,EAAc,aAAO,MACrB,EAAS,SAAY,MACrB,EAAqB,SAAY,MACjC,EAAe,WAEf,EAAsB,kBAC1B,CAAC,EAAU,OAAS,CAClB,EAAiB,SACf,GAAY,QAAU,GAAI,GAAY,EAAe,GACrD,EAAY,QAAQ,QAAU,IAE5B,IAAY,IACd,GAAU,CAAC,GAEb,EAAY,QAAQ,oBAAoB,GACxC,EAA0B,IAE5B,CAAC,IAGH,sBAAU,IAAM,CACd,EAAU,EAAO,UAAU,WAAW,KACtC,EAAQ,KAAK,uBAAwB,CAAC,CAAE,UAAW,CACjD,GAAI,EAAM,CACR,GAAI,GAAsB,KAAK,MAAM,GACrC,GAA2B,EAAoB,oBAE7C,EACG,IACC,EAAoB,oBAAoB,WAG5C,GACA,EAAoB,UACpB,EAAoB,aAAe,IAMnC,GAAc,EAAoB,YAClC,EAAgB,IAAM,EAAoB,SAAW,KACjD,EAAoB,WAAa,CAAC,GACpC,IAEF,WAAW,IAAM,CACf,EAAc,IACd,EAAgB,KACf,UAIR,CAAC,EAAQ,EAAwB,IAEpC,gBAAU,IAAM,CACd,CAAK,GAIH,EAAY,SACZ,GACA,EAAa,OAAS,kBAEtB,EAAY,QAAQ,UAClB,KAAK,UAAU,CAAE,oBAAqB,CAAE,UAAW,QAGtD,CAAC,EAAc,IAGhB,gCACE,gBAAC,IAAD,CACE,IAAK,CACH,UAAW,OACX,WAAY,UACZ,OAAQ,QACR,SAAU,QACV,MAAO,OACP,SAAU,QACV,OAAQ,UACR,MAAO,QACP,WAAY,mBACZ,WAAY,WACZ,YAAa,UAGjB,gBAAC,IAAD,CACE,IAAK,CACH,UAAW,SACX,WAAY,UACZ,OAAQ,OACR,SAAU,QACV,MAAO,OACP,SAAU,QACV,OAAQ,UACR,MAAO,QACP,WAAY,mBACZ,WAAY,aAGd,gBAAC,IAAD,CACE,IAAK,CACH,MAAO,QACP,WAAY,qBAGb,GAEH,gBAAC,IAAD,CACE,IAAK,CACH,MAAO,UACP,WAAY,mBACZ,cAAe,eAGhB,IAGJ,EAAmB,OAClB,gBAAC,IAAD,CACE,MAAO,QAAQ,EAAiC,MAAP,sBAEzC,gBAAC,IAAD,CACE,IAAK,CAAE,GAAI,MACX,OAAQ,CAAC,EACT,QAAS,EACT,cAAY,qBAEZ,gBAAC,IAAD,SAOZ,OAAkB,CAChB,YAAY,EAAe,EAAiB,CAmB5C,mBAAY,CAAC,EAAM,EAAY,kBAAoB,CACjD,EAAQ,QAAQ,UAAU,IAAa,CAAE,OAAM,gBAnB/C,KAAK,QAAU,GACf,KAAK,OAAS,KACd,KAAK,cAAgB,EACrB,KAAK,WAAa,EAClB,KAAK,QAAU,GACf,KAAK,cAAgB,EACrB,KAAK,gBAAkB,EACvB,KAAK,YAAc,GACnB,KAAK,YAAc,GACnB,KAAK,YAAc,KACnB,KAAK,gBAAkB,CACrB,UAAW,IACX,gBAAiB,IACjB,sBAAuB,EACvB,WAAY,KAQV,QAAS,gCACb,GAAI,CACF,KAAM,GAAY,OAAO,MAAM,IAAI,eACnC,KAAK,YAAc,EAAU,OAC7B,KAAK,QAAQ,EAAU,QAAU,CAC/B,OAAQ,GAAI,aAAY,CAAC,EAAU,WAAW,cAC9C,KAAM,EAAU,MAGlB,GAAI,GAAM,4jOAAY,gDAElB,EAAO,KAAM,MADD,OAAM,IACD,OACrB,GAAI,GAAQ,EAAK,MAAO,CACtB,KAAM,GAAQ,EAAK,MACnB,KAAK,OAAS,KAAM,IAAI,WACtB,uDAAuD,KAAK,gBAAgB,yBAAyB,KAEvG,KAAK,cAAc,IACnB,KAAK,OAAO,UAAY,GAAW,CACjC,GAAI,CACF,KAAM,GAAM,KAAK,MAAM,EAAQ,MAC/B,GAAI,EAAI,MAAQ,KAAK,QAAS,CAC5B,GAAI,GAAW,KAAK,QAAQ,KAAK,aAAa,KAE1C,EACF,EAAI,KAAK,QAAU,GACf,EAAI,KACD,MAAM,KACN,MAAM,KAAK,IAAI,EAAI,KAAK,MAAM,KAAK,OAAS,GAAI,IAChD,KAAK,KACR,EAAI,KACV,KAAK,cAAc,GACnB,KAAK,gBAAgB,SACrB,WAAW,IAAM,CACf,KAAK,cAAc,IACnB,KAAK,gBAAgB,KACpB,KACH,KAAK,UACH,KAAK,UAAU,CACb,WACA,WAAY,EACZ,UAAW,KAAK,kBAIf,EAJe,CAKtB,QAAQ,MAAM,gBAAiB,KAInC,KAAK,OAAO,QAAU,GAAS,CAC7B,QAAQ,MAAM,gBAAiB,GAC/B,KAAK,OAAO,SAGd,KAAK,OAAO,QAAU,GAAS,CAC7B,GAAI,CACF,QAAQ,IAAI,GACZ,KAAK,OAAS,KACV,KAAK,SACP,KAAK,eAEA,EAFA,CAGP,QAAQ,MAAM,gBAAiB,KAInC,KAAK,OAAO,OAAS,IAAM,CACzB,GAAI,CACF,OAAS,KAAK,MAAK,QACjB,KAAK,cAAc,KAAK,QAAQ,GAAG,cAE9B,EAF8B,CAGrC,QAAQ,MAAM,gBAAiB,SAInC,SAAQ,IAAI,yCAEP,EAFO,CAGd,QAAQ,MAAM,gBAAiB,MAI7B,cAAc,EAAQ,gCA4B1B,GA3BmB,MAAU,EAAQ,OAChC,KAAK,iBAD2B,CAEnC,KAAM,QACN,SAAU,wBACV,aAAc,sBACd,gBAAiB,GAAQ,CACvB,KAAM,GAAS,GAAI,YACnB,EAAO,OAAS,IAAM,CACpB,KAAM,GAAa,EAAO,OAC1B,GACE,KAAK,QACL,KAAK,SACL,KAAK,OAAO,YACZ,KAAK,OAAO,aAAe,EAE3B,GAAI,CACF,KAAK,OAAO,KACV,KAAK,UAAU,CAAE,WAAY,EAAW,MAAM,WAAW,YAEpD,EAFoD,CAG3D,QAAQ,MAAM,gBAAiB,KAIrC,EAAO,cAAc,OAGhB,mBAGX,oBAAoB,EAAQ,CAC1B,GAAc,CAAC,KAAK,QAClB,MAAK,QAAU,GACf,KAAK,SACL,KAAK,UACH,KAAK,UAAU,CAAE,oBAAqB,CAAE,UAAW,QAE5C,CAAC,GAAU,KAAK,SACzB,MAAK,UACH,KAAK,UAAU,CAAE,oBAAqB,CAAE,UAAW,OAErD,KAAK,QAAU,GACf,KAAK,OAAO,QACZ,KAAK,OAAS,KACd,WAAW,IAAM,CACf,KAAK,cAAc,KAClB","sources":["plugins/transcription/TranscriptionButton.jsx"],"sourcesContent":["import { useCallback, useEffect, useRef, useState } from \"react\";\nimport Pusher from \"pusher-js\";\nimport {\n  useHMSStore,\n  selectIsAllowedToPublish,\n  useHMSNotifications,\n  HMSNotificationTypes,\n  selectRoomID,\n} from \"@100mslive/react-sdk\";\nimport RecordRTC, { StereoAudioRecorder } from \"recordrtc\";\nimport { Box, Tooltip, Text, IconButton } from \"@100mslive/react-ui\";\nimport { ClosedCaptionIcon } from \"@100mslive/react-icons\";\nimport { FeatureFlags } from \"../../services/FeatureFlags\";\n\nconst pusher =\n  FeatureFlags.enableTranscription &&\n  new Pusher(process.env.REACT_APP_TRANSCRIPTION_PUSHER_APP_KEY, {\n    cluster: \"ap2\",\n    authEndpoint: process.env.REACT_APP_TRANSCRIPTION_PUSHER_AUTHENDPOINT,\n  });\nlet channel = null;\n\nexport function TranscriptionButton() {\n  const [isTranscriptionEnabled, setIsTranscriptionEnabled] = useState(false);\n  const [transcript, setTranscript] = useState(\"\");\n  const [speakingPeer, setSpeakingPeer] = useState(\"\");\n  const transcriber = useRef(null);\n  const roomId = useHMSStore(selectRoomID);\n  const isAllowedToPublish = useHMSStore(selectIsAllowedToPublish);\n  const notification = useHMSNotifications();\n\n  const enableTranscription = useCallback(\n    (enabled = null) => {\n      if (!transcriber.current) {\n        transcriber.current = new Transcriber(setTranscript, setSpeakingPeer);\n        transcriber.current.enabled = false;\n      }\n      if (enabled !== false) {\n        enabled = !isTranscriptionEnabled;\n      }\n      transcriber.current.enableTranscription(enabled);\n      setIsTranscriptionEnabled(enabled);\n    },\n    [isTranscriptionEnabled]\n  );\n\n  useEffect(() => {\n    channel = pusher.subscribe(`private-${roomId}`);\n    channel.bind(`client-transcription`, ({ text }) => {\n      if (text) {\n        let remoteTranscription = JSON.parse(text);\n        if (remoteTranscription && remoteTranscription.transcriptionConfig) {\n          // Remote Peer is enabled/disabled the transcription feature\n          enableTranscription(\n            (isTranscriptionEnabled ? false : true) &&\n              remoteTranscription.transcriptionConfig.isEnabled\n          );\n        } else if (\n          remoteTranscription &&\n          remoteTranscription.peername &&\n          remoteTranscription.transcript !== \"\"\n        ) {\n          /**\n           *  Remote Peername and his Transcripts should be there on results. If those are missing, something goes wrong in the broadcast flow.\n           *  If any failure happens, we won't display any subtitle texts on the UI.\n           **/\n          setTranscript(remoteTranscription.transcript);\n          setSpeakingPeer(\"[\" + remoteTranscription.peername + \"]\");\n          if (remoteTranscription.isEnabled && !isTranscriptionEnabled) {\n            enableTranscription();\n          }\n          setTimeout(() => {\n            setTranscript(\"\");\n            setSpeakingPeer(\"\");\n          }, 5000);\n        }\n      }\n    });\n  }, [roomId, isTranscriptionEnabled, enableTranscription]);\n\n  useEffect(() => {\n    if (!notification) {\n      return;\n    }\n    if (\n      transcriber.current &&\n      isTranscriptionEnabled &&\n      notification.type === HMSNotificationTypes.PEER_JOINED\n    ) {\n      transcriber.current.broadcast(\n        JSON.stringify({ transcriptionConfig: { isEnabled: true } })\n      );\n    }\n  }, [notification, isTranscriptionEnabled]);\n\n  return (\n    <>\n      <Box\n        css={{\n          textAlign: \"left\",\n          fontWeight: \"$medium\",\n          bottom: \"120px\",\n          position: \"fixed\",\n          width: \"100%\",\n          fontSize: \"$20px\",\n          zIndex: \"1000000\",\n          color: \"white\",\n          textShadow: \"0px 0px 6px #000\",\n          whiteSpace: \"pre-line\",\n          paddingLeft: \"40px\",\n        }}\n      />\n      <Box\n        css={{\n          textAlign: \"center\",\n          fontWeight: \"$medium\",\n          bottom: \"90px\",\n          position: \"fixed\",\n          width: \"100%\",\n          fontSize: \"$20px\",\n          zIndex: \"1000000\",\n          color: \"white\",\n          textShadow: \"0px 0px 6px #000\",\n          whiteSpace: \"pre-line\",\n        }}\n      >\n        <Text\n          css={{\n            color: \"white\",\n            textShadow: \"0px 0px 6px #000\",\n          }}\n        >\n          {transcript}\n        </Text>\n        <Text\n          css={{\n            color: \"#c0bbbb\",\n            textShadow: \"0px 0px 6px #000\",\n            textTransform: \"capitalize\",\n          }}\n        >\n          {speakingPeer}\n        </Text>\n      </Box>\n      {isAllowedToPublish.audio && (\n        <Tooltip\n          title={`Turn ${!isTranscriptionEnabled ? \"on\" : \"off\"} transcription`}\n        >\n          <IconButton\n            css={{ mx: \"$4\" }}\n            active={!isTranscriptionEnabled}\n            onClick={enableTranscription}\n            data-testid=\"transcription_btn\"\n          >\n            <ClosedCaptionIcon />\n          </IconButton>\n        </Tooltip>\n      )}\n    </>\n  );\n}\nclass Transcriber {\n  constructor(setTranscript, setSpeakingPeer) {\n    this.enabled = false;\n    this.socket = null;\n    this.totalTimeDiff = 0;\n    this.totalCount = 0;\n    this.streams = {};\n    this.setTranscript = setTranscript;\n    this.setSpeakingPeer = setSpeakingPeer;\n    this.initialized = false;\n    this.lastMessage = {};\n    this.localPeerId = null;\n    this.sttTuningConfig = {\n      timeSlice: 250,\n      desiredSampRate: 8000,\n      numberOfAudioChannels: 1,\n      bufferSize: 256,\n    };\n  }\n\n  broadcast = (text, eventName = \"transcription\") => {\n    channel.trigger(`client-${eventName}`, { text, eventName });\n  };\n\n  async listen() {\n    try {\n      const localPeer = window.__hms.sdk.getLocalPeer();\n      this.localPeerId = localPeer.peerId;\n      this.streams[localPeer.peerId] = {\n        stream: new MediaStream([localPeer.audioTrack.nativeTrack]),\n        name: localPeer.name,\n      };\n\n      let url = process.env.REACT_APP_DYNAMIC_STT_TOKEN_GENERATION_ENDPOINT;\n      let res = await fetch(url);\n      let body = await res.json();\n      if (body && body.token) {\n        const token = body.token;\n        this.socket = await new WebSocket(\n          `wss://api.assemblyai.com/v2/realtime/ws?sample_rate=${this.sttTuningConfig.desiredSampRate}&token=${token}`\n        );\n        this.setTranscript(\"\");\n        this.socket.onmessage = message => {\n          try {\n            const res = JSON.parse(message.data);\n            if (res.text && this.enabled) {\n              let peername = this.streams[this.localPeerId][\"name\"];\n              //Limiting the transcript size based on it's charecter length.\n              let messageText =\n                res.text.length >= 80\n                  ? res.text\n                      .split(\" \")\n                      .slice(Math.max(res.text.split(\" \").length - 10, 1))\n                      .join(\" \")\n                  : res.text;\n              this.setTranscript(messageText);\n              this.setSpeakingPeer(\"[You]\");\n              setTimeout(() => {\n                this.setTranscript(\"\");\n                this.setSpeakingPeer(\"\");\n              }, 5000);\n              this.broadcast(\n                JSON.stringify({\n                  peername: peername,\n                  transcript: messageText,\n                  isEnabled: this.enabled,\n                })\n              );\n            }\n          } catch (err) {\n            console.error(\"transcription\", err);\n          }\n        };\n\n        this.socket.onerror = event => {\n          console.error(\"transcription\", event);\n          this.socket.close();\n        };\n\n        this.socket.onclose = event => {\n          try {\n            console.log(event);\n            this.socket = null;\n            if (this.enabled) {\n              this.listen();\n            }\n          } catch (err) {\n            console.error(\"transcription\", err);\n          }\n        };\n\n        this.socket.onopen = () => {\n          try {\n            for (let i in this.streams) {\n              this.observeStream(this.streams[i][\"stream\"]);\n            }\n          } catch (err) {\n            console.error(\"transcription\", err);\n          }\n        };\n      } else {\n        console.log(\"Unable to fetch dynamic token!!\");\n      }\n    } catch (err) {\n      console.error(\"transcription\", err);\n    }\n  }\n\n  async observeStream(stream) {\n    let recorder = new RecordRTC(stream, {\n      ...this.sttTuningConfig,\n      type: \"audio\",\n      mimeType: \"audio/webm;codecs=pcm\",\n      recorderType: StereoAudioRecorder,\n      ondataavailable: blob => {\n        const reader = new FileReader();\n        reader.onload = () => {\n          const base64data = reader.result;\n          if (\n            this.socket &&\n            this.enabled &&\n            this.socket.readyState &&\n            this.socket.readyState === 1\n          ) {\n            try {\n              this.socket.send(\n                JSON.stringify({ audio_data: base64data.split(\"base64,\")[1] })\n              );\n            } catch (err) {\n              console.error(\"transcription\", err);\n            }\n          }\n        };\n        reader.readAsDataURL(blob);\n      },\n    });\n    recorder.startRecording();\n  }\n\n  enableTranscription(enable) {\n    if (enable && !this.enabled) {\n      this.enabled = true;\n      this.listen();\n      this.broadcast(\n        JSON.stringify({ transcriptionConfig: { isEnabled: true } })\n      );\n    } else if (!enable && this.enabled) {\n      this.broadcast(\n        JSON.stringify({ transcriptionConfig: { isEnabled: false } })\n      );\n      this.enabled = false;\n      this.socket.close();\n      this.socket = null;\n      setTimeout(() => {\n        this.setTranscript(\"\");\n      }, 200);\n    }\n  }\n}\n"],"names":[],"sourceRoot":""}